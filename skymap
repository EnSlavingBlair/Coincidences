#!/usr/bin/env python
# coding: utf-8

# Following the tutorial at https://emfollow.docs.ligo.org/userguide/tutorial/skymaps.html

import healpy as hp
import numpy as np
import os
import matplotlib.pyplot as plt


def get_map(event, basepath_loc):
    # get normalised map for input event name
    basepath = basepath_loc + event + '/'
    for entry in os.listdir(basepath):
        if os.path.isfile(os.path.join(basepath, entry)):
            map_pdf = hp.read_map(basepath+entry, verbose=False)
            return map_pdf / (4 * np.pi / len(map_pdf))  # to get normalisation of posterior st p*d_Omega = 1


def coinc(hpx1, hpx2, event1, event2):
    # get significance of two event localisations, following localisation significance method from Ashton et al 2018
    N_points = len(hpx1)  # value taken from Ashton et al 2018 code is 12*2**12
    d_Omega = 4 * np.pi / N_points  # size of pixels
    prior = 1 / (4 * np.pi)  # uniform prior over the whole sky
    # view what the maps look like plotted together
    add = (hpx1 + hpx2)/2
    hp.mollview(add)
    plt.title(str(event1)+" and "+str(event2)+" mean")
    plt.savefig("data/joint_localisation_maps/"+str(event1)+"-"+str(event2)+"-add")
    # view what the maps look like following significance method in the log scale
    mult = hpx1 * hpx2
    I_Omega = sum(mult) / prior * d_Omega # the significance of interest
    exp = np.floor(np.log10(np.abs(I_Omega))).astype(int)
    hp.mollview(mult / prior * d_Omega)
    plt.title(str(event1)+" and "+str(event2)+": $log10(I_\Omega) = $"+str(I_Omega))
    plt.savefig("data/joint_localisation_maps/"+str(event1)+"-"+str(event2)+"-IOmega"+str(exp))
    return I_Omega


def shape_maps(map1, map2):
    # reshape the event maps to be the same size
    nside = max(hp.pixelfunc.get_nside(map1), hp.pixelfunc.get_nside(map2))
    return hp.pixelfunc.ud_grade(map1, nside), hp.pixelfunc.ud_grade(map2, nside)


# The path to the folder that stores the fits files for each event of interest
# each in its own folder named after the eg. GraceDB event name (for GW events)
# basepath_loc = 'data/sky_localisations/'
basepath_loc1 = 'data/170817_event_loc/'
basepath_loc2 = 'data/170817_event_loc/'
basepath_time = 'data/170817_event_time/'
basepath_rate = 'data/170817_event_rate/'

# events to contain a string of each of the event names of interest eg. ['gw200213']
events1 = []
events2 = []
times = []
for entry in os.listdir(basepath_loc1):
    if os.path.isdir(os.path.join(basepath_loc1, entry)):
        events1.append(entry)

for entry in os.listdir(basepath_loc2):
    if os.path.isdir(os.path.join(basepath_loc2, entry)):
        events2.append(entry)

for entry in os.listdir(basepath_time):
    with open(basepath_time + entry, 'r') as f:
        times.append(np.float(f.readline()))

for entry in os.listdir(basepath_rate):
    with open(basepath_rate + entry, 'r') as f:
        em_rates = np.float(f.readline())/(24*60*60)  # rates in per second

# will write the most significant coincidences found using this method to "significant_coincidences.txt"
f = open("significant_coincidences.txt","w")

# Compare each event with each other event with no double ups
for idx1 in range(len(events1)):
    for idx2 in range(idx1+1, len(events2)):
        print(str(idx1)+"/"+str(len(events1))+" : "+str(idx2)+"/"+str(len(events2)))  # shows progress
        I_Omega = "may be different shapes"  # will print if rest doesn't work
        if events1[idx1] != events2[idx2]:  # avoiding comparing event to itself
            map1 = get_map(events1[idx1], basepath_loc1)  # get normalised map for event
            print("map1: "+events1[idx1])
            map2 = get_map(events2[idx2], basepath_loc2)  # get normalised map for event
            print("map2: "+events2[idx2])
            map1, map2 = shape_maps(map1, map2)  # set maps to be the same size
            print("Maps now the same size")
            I_Omega = coinc(map1, map2, events1[idx1], events2[idx2]) # following Ashton et al 2018 to get significance
            print("I_Omega for " + str(events1[idx1]) + " and " + str(events2[idx2]) + ": " + str(I_Omega))
            if I_Omega >= 1: # write significance events to "significant_coincidences.txt"
                f.write(str(events1[idx1]) + "   " + str(events2[idx2]) + "   " + str(I_Omega) + "    " + str(times[idx2] - times[idx1]) + "    " + str(em_rates) + "   " + str(1/em_rates * 1/np.abs(times[idx2]-times[idx1]) * I_Omega) + "\n")
        elif events1[idx1] == events2[idx2]:  # double for loop at start should avoid this, prints if it doesn't work
            print("Tried comparing to itself")

f.close()

# test one map with itself - should be >> 1 (probably around 200+)
idx = 1
map1 = get_map(events1[idx], basepath_loc1)
map2 = get_map(events2[idx], basepath_loc2)
map1, map2 = shape_maps(map1, map2)
I_Omega = coinc(map1, map2, events1[idx], events2[idx])
print("I_Omega: "+str(I_Omega))
